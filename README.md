# 🌐 Sign Language to Voice and Text Translator Web Application

This web application translates **sign language gestures** into **text** and **voice output** using advanced AI and computer vision techniques. The solution aims to bridge the communication gap for the deaf and hard-of-hearing community by offering real-time interpretation through a web interface.

---

## 📌 Project Overview

The project leverages cutting-edge deep learning models and computer vision to:

- Capture real-time hand gestures via a webcam
- Recognize and interpret signs using a GRU-based model
- Translate the signs into text
- Convert the recognized text to human-like voice using TTS

Developed as a part of our Artificial Intelligence coursework to apply theoretical knowledge in a real-world assistive technology solution.

---

## 👥 Team Members

- **Pema Chozom**
- **Pema Yangchen**
- **Thukten Dema**
- **Asseh Nepal**
- **Bidash Gurung**

---

## 🧠 Technologies & Tools Used

| Technology        | Purpose                                       |
|-------------------|-----------------------------------------------|
| **React**         | Front-end development for user interface      |
| **Node.js**       | Back-end server for handling requests         |
| **OpenCV**        | Real-time gesture recognition (Computer Vision) |
| **GRU Model**     | Sequential learning for sign recognition      |
| **Text-to-Speech**| Voice output from translated text             |
| **Python**        | Model training and preprocessing              |
| **TensorFlow.js** | AI model integration in web applications      |

---

## 📱 App Features

- 📷 Real-time hand gesture recognition using webcam
- 📝 Live text output of recognized sign language
- 🔊 Text-to-Speech (TTS) conversion from recognized text
- 🌐 Accessible on multiple devices via web browser
- 🧩 User-friendly and intuitive interface

---

## 🎨 UI/UX Design

The UI is designed with accessibility in mind:

- ✅ Large buttons for easy interaction  
- ✅ Live webcam feedback for gesture tracking  
- ✅ Toggle switch to enable/disable voice output  
- ✅ Simple step-by-step instructions for usage  

---

## 🎯 Learning Outcomes

- 🤖 Gained hands-on experience training and deploying GRU models
- 🎥 Learned computer vision basics for gesture recognition using OpenCV
- 📲 Understood how to integrate AI models in web applications using TensorFlow.js
- 🔊 Implemented Text-to-Speech features for accessibility
- 🔗 Successfully integrated AI models into real-time web apps
- 🤝 Strengthened teamwork and project collaboration in a tech team
- 🧠 Enhanced problem-solving and debugging skills in web development

---

## ✅ Project Status

- ✔️ MVP completed and tested
- ✔️ Fully functional real-time gesture-to-text-to-speech translation
- ✔️ Presented as a part of coursework in Artificial Intelligence

---

## 🚀 Future Improvements

- 🔄 Extend gesture recognition to full sentence structures
- 🌍 Add multi-language TTS support
- 👤 Introduce user training for personalized gesture sets
- 🤖 Use transformer models for improved contextual understanding
- 🇧🇹 Expand dataset to support Bhutanese Sign Language (BSL)

