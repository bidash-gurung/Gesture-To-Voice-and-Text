# ğŸŒ Sign Language to Voice and Text Translator Web Application

This web application translates **sign language gestures** into **text** and **voice output** using advanced AI and computer vision techniques. The solution aims to bridge the communication gap for the deaf and hard-of-hearing community by offering real-time interpretation through a web interface.

---

## ğŸ“Œ Project Overview

The project leverages cutting-edge deep learning models and computer vision to:

- Capture real-time hand gestures via a webcam
- Recognize and interpret signs using a GRU-based model
- Translate the signs into text
- Convert the recognized text to human-like voice using TTS

Developed as a part of our Artificial Intelligence coursework to apply theoretical knowledge in a real-world assistive technology solution.

---

## ğŸ‘¥ Team Members

- **Pema Chozom**
- **Pema Yangchen**
- **Thukten Dema**
- **Asseh Nepal**
- **Bidash Gurung**

---

## ğŸ§  Technologies & Tools Used

| Technology        | Purpose                                       |
|-------------------|-----------------------------------------------|
| **React**         | Front-end development for user interface      |
| **Node.js**       | Back-end server for handling requests         |
| **OpenCV**        | Real-time gesture recognition (Computer Vision) |
| **GRU Model**     | Sequential learning for sign recognition      |
| **Text-to-Speech**| Voice output from translated text             |
| **Python**        | Model training and preprocessing              |
| **TensorFlow.js** | AI model integration in web applications      |

---

## ğŸ“± App Features

- ğŸ“· Real-time hand gesture recognition using webcam
- ğŸ“ Live text output of recognized sign language
- ğŸ”Š Text-to-Speech (TTS) conversion from recognized text
- ğŸŒ Accessible on multiple devices via web browser
- ğŸ§© User-friendly and intuitive interface

---

## ğŸ¨ UI/UX Design

The UI is designed with accessibility in mind:

- âœ… Large buttons for easy interaction  
- âœ… Live webcam feedback for gesture tracking  
- âœ… Toggle switch to enable/disable voice output  
- âœ… Simple step-by-step instructions for usage  

---

## ğŸ¯ Learning Outcomes

- ğŸ¤– Gained hands-on experience training and deploying GRU models
- ğŸ¥ Learned computer vision basics for gesture recognition using OpenCV
- ğŸ“² Understood how to integrate AI models in web applications using TensorFlow.js
- ğŸ”Š Implemented Text-to-Speech features for accessibility
- ğŸ”— Successfully integrated AI models into real-time web apps
- ğŸ¤ Strengthened teamwork and project collaboration in a tech team
- ğŸ§  Enhanced problem-solving and debugging skills in web development

---

## âœ… Project Status

- âœ”ï¸ MVP completed and tested
- âœ”ï¸ Fully functional real-time gesture-to-text-to-speech translation
- âœ”ï¸ Presented as a part of coursework in Artificial Intelligence

---

## ğŸš€ Future Improvements

- ğŸ”„ Extend gesture recognition to full sentence structures
- ğŸŒ Add multi-language TTS support
- ğŸ‘¤ Introduce user training for personalized gesture sets
- ğŸ¤– Use transformer models for improved contextual understanding
- ğŸ‡§ğŸ‡¹ Expand dataset to support Bhutanese Sign Language (BSL)

